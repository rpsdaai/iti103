{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/2021S1_ml_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exxTxlIdTB3L",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# ITI103: Essentials of Machine Learning - Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS7fHzUeTB3M",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment, you will work a data set based on [housing prices in Ames, Iowa](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). It is a modernized alternative to the well-known Boston Housing dataset. \n",
    "\n",
    "You may access the dataset from [https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignments/data/ames_house_prices_simple.csv) For a detailed description of each field (feature), you can refer to the following [file](https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignments/data/data_description.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PSXulFb9U0ck"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 200) \n",
    "pd.set_option('display.max_rows',200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CGm2OgTB3N",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 1 (2 marks)\n",
    "\n",
    "Complete the code below and answer the following: \n",
    "- How many rows and columns are there?\n",
    "- What are the different data types of the columns? \n",
    "\n",
    "_Type your answer here_\n",
    "\n",
    "rows = 1379\n",
    "cols = 40\n",
    "\n",
    "There are 3 different data types for the columns, namely, int64, float64 and object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O71PVNVLTB3O",
    "outputId": "64674c28-1510-4e1d-9c38-5c2c08e40803",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: \n",
      " (1379, 40)\n",
      "Dataframe Info\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1379 entries, 0 to 1378\n",
      "Data columns (total 40 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   OverallQual    1379 non-null   int64  \n",
      " 1   GrLivArea      1379 non-null   float64\n",
      " 2   TotalBsmtSF    1379 non-null   float64\n",
      " 3   2ndFlrSF       1379 non-null   float64\n",
      " 4   1stFlrSF       1379 non-null   float64\n",
      " 5   BsmtFinSF1     1379 non-null   float64\n",
      " 6   GarageCars     1379 non-null   int64  \n",
      " 7   FullBath       1379 non-null   int64  \n",
      " 8   GarageArea     1379 non-null   float64\n",
      " 9   LotArea        1379 non-null   float64\n",
      " 10  MasVnrArea     1379 non-null   float64\n",
      " 11  YearBuilt      1379 non-null   int64  \n",
      " 12  YearRemodAdd   1379 non-null   int64  \n",
      " 13  GarageYrBlt    1379 non-null   float64\n",
      " 14  BsmtUnfSF      1379 non-null   float64\n",
      " 15  BsmtQual       1379 non-null   object \n",
      " 16  LotFrontage    1379 non-null   float64\n",
      " 17  OpenPorchSF    1379 non-null   float64\n",
      " 18  OverallCond    1379 non-null   int64  \n",
      " 19  GarageType     1379 non-null   object \n",
      " 20  WoodDeckSF     1379 non-null   float64\n",
      " 21  TotRmsAbvGrd   1379 non-null   int64  \n",
      " 22  MSSubClass     1379 non-null   int64  \n",
      " 23  MoSold         1379 non-null   int64  \n",
      " 24  BsmtExposure   1379 non-null   object \n",
      " 25  LotShape       1379 non-null   object \n",
      " 26  MSZoning       1379 non-null   object \n",
      " 27  BedroomAbvGr   1379 non-null   int64  \n",
      " 28  MasVnrType     1379 non-null   object \n",
      " 29  ExterQual      1379 non-null   object \n",
      " 30  HalfBath       1379 non-null   int64  \n",
      " 31  FireplaceQu    1379 non-null   object \n",
      " 32  KitchenQual    1379 non-null   object \n",
      " 33  Condition1     1379 non-null   object \n",
      " 34  BldgType       1379 non-null   object \n",
      " 35  SaleCondition  1379 non-null   object \n",
      " 36  Street         1379 non-null   object \n",
      " 37  PavedDrive     1379 non-null   object \n",
      " 38  SaleType       1379 non-null   object \n",
      " 39  SalePrice      1379 non-null   float64\n",
      "dtypes: float64(14), int64(11), object(15)\n",
      "memory usage: 431.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## START YOUR CODE\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data \n",
    "url = 'https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignments/data/ames_house_prices_simple.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print (\"Dataframe shape: \\n\", df.shape)\n",
    "# Display value counts of each data type\n",
    "# Ref: https://stackoverflow.com/questions/22470690/get-list-of-pandas-dataframe-columns-based-on-data-type\n",
    "# list(df.select_dtypes(['object']).columns)\n",
    "#print (\"Selected dataframe columns based on specified type: \\n\", df.select_dtypes(include='object').columns)\n",
    "\n",
    "#print (\"value counts: \\n\", df.value_counts())\n",
    "\n",
    "print (\"Dataframe Info\\n\")\n",
    "print (df.info())\n",
    "## END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6TH2a6mTB3T",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 2 (5 marks)\n",
    "\n",
    "Examine the column dtype and read the column description in data_description.txt.  Determine which columns are categorical. Create a list that contains the column names that are categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xOFa41z3TB3U",
    "outputId": "bc6e36f1-1660-4f7e-fb3a-db1f01fd0ae4",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: \n",
      " ['BsmtQual', 'GarageType', 'BsmtExposure', 'LotShape', 'MSZoning', 'MasVnrType', 'ExterQual', 'FireplaceQu', 'KitchenQual', 'Condition1', 'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType'] \n",
      "\n",
      "Numerical Columns:  ['OverallQual', 'GarageCars', 'FullBath', 'YearBuilt', 'YearRemodAdd', 'OverallCond', 'TotRmsAbvGrd', 'MSSubClass', 'MoSold', 'BedroomAbvGr', 'HalfBath'] \n",
      "\n",
      "Additional Numerical Categorical Columns:  ['YearRemodAdd', 'YearBuilt', 'OverallQual', 'MSSubClass', 'MoSold', 'OverallCond', 'GarageYrBlt'] \n",
      "\n",
      "FP Columns:  ['GrLivArea', 'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1', 'GarageArea', 'LotArea', 'MasVnrArea', 'BsmtUnfSF', 'LotFrontage', 'OpenPorchSF', 'WoodDeckSF', 'GarageCars', 'FullBath', 'TotRmsAbvGrd', 'BedroomAbvGr', 'HalfBath', 'SalePrice'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## START YOUR CODE\n",
    "\n",
    "# Get the list of column names that are object type\n",
    "# Ref: https://stackoverflow.com/questions/22470690/get-list-of-pandas-dataframe-columns-based-on-data-type\n",
    "# Ref: https://nycdatascience.com/blog/student-works/machine-learning-house-price-prediction-ames-iowa/\n",
    "# Ref: https://jovian.ai/seanbenhur/ames-housing\n",
    "# Ref: https://towardsdatascience.com/wrangling-through-dataland-modeling-house-prices-in-ames-iowa-75b9b4086c96\n",
    "# Ref: https://www.kaggle.com/erick5/predicting-house-prices-with-machine-learning\n",
    "\n",
    "cat_attribs = list(df.select_dtypes(['object']).columns)     \n",
    "print ('Categorical Columns: \\n', cat_attribs, '\\n')\n",
    "\n",
    "# add additional column name that you think should be categorical\n",
    "# more = ['MSSubClass', 'OverallQual', 'OverallCond']\n",
    "# additional_categorical_cols = ['MSSubClass', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold']\n",
    "# print (\"Additional Categorical columns: \\n\", additional_categorical_cols)\n",
    "\n",
    "# categorical_cols.extend(more)\n",
    "# print (\"Extended Categorical columns: \\n\", categorical_cols)\n",
    "\n",
    "num_attribs = list(df.select_dtypes(['int64']).columns)\n",
    "print ('Numerical Columns: ', num_attribs, '\\n')\n",
    "\n",
    "# Ref: https://stackoverflow.com/questions/36268749/remove-multiple-items-from-a-python-list-in-just-one-statement\n",
    "list_to_remove = ['GarageCars', 'FullBath', 'TotRmsAbvGrd', 'BedroomAbvGr', 'HalfBath']\n",
    "num_attribs = list(set(num_attribs) - set(list_to_remove))\n",
    "num_attribs.append('GarageYrBlt')\n",
    "print ('Additional Numerical Categorical Columns: ', num_attribs, '\\n')\n",
    "\n",
    "fp_attribs = list(df.select_dtypes(['float64']).columns)\n",
    "# Drop 'GarageYrBlt'. This has been moved to the num_attributes list above\n",
    "fp_attribs.remove('GarageYrBlt')\n",
    "# fp_attribs.insert(len(fp_attribs), list_to_remove) this will create a list within list\n",
    "# Ref: https://www.geeksforgeeks.org/python-insert-list-in-another-list/\n",
    "fp_attribs[len(fp_attribs)-1:len(fp_attribs)-1] = list_to_remove\n",
    "print ('FP Columns: ', fp_attribs, '\\n')\n",
    "\n",
    "## END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W195EUbxU0cp"
   },
   "source": [
    "### Question 3 (8 marks)\n",
    "\n",
    "Think about the 'YearBuilt' and 'MoSold' columns (which represent the year the house is built and the month it was sold). They are of numeric (integer) type. Should you transform it?  Give your reason for the answer.\n",
    "\n",
    "If your answer is 'Yes', write the code to transform it.\n",
    "\n",
    "_Type your answer here_\n",
    "\n",
    "Yes, **(YearBuilt)** age of house & **(MoSold)** month sold could affect housing price; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fT_wWnvsU0cq"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original dataframe and do all the processing on the copy \n",
    "# use the data for subsequent cells\n",
    "\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xj3K9pgIU0cr",
    "outputId": "b15536a4-7fcb-4fcb-c9fa-a5d53a4f9c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Years:  109 \n",
      "\n",
      "existing columns: \n",
      " ['OverallQual', 'GrLivArea', 'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1', 'GarageCars', 'FullBath', 'GarageArea', 'LotArea', 'MasVnrArea', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'BsmtUnfSF', 'BsmtQual', 'LotFrontage', 'OpenPorchSF', 'OverallCond', 'GarageType', 'WoodDeckSF', 'TotRmsAbvGrd', 'MSSubClass', 'MoSold', 'BsmtExposure', 'LotShape', 'MSZoning', 'BedroomAbvGr', 'MasVnrType', 'ExterQual', 'HalfBath', 'FireplaceQu', 'KitchenQual', 'Condition1', 'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType', 'SalePrice'] \n",
      "\n",
      "sorted: \n",
      " 1880-1900     21\n",
      "1901-1910     17\n",
      "1911-1920     56\n",
      "1921-1930     66\n",
      "1931-1940     55\n",
      "1941-1950     73\n",
      "1951-1960    157\n",
      "1961-1970    176\n",
      "1971-1980    164\n",
      "1981-1990     60\n",
      "1991-2000    173\n",
      "2001-2010    361\n",
      "Name: YearBuilt_cat, dtype: int64 \n",
      "\n",
      "Binned Month Sold: \n",
      " 0       winter\n",
      "1       spring\n",
      "2       autumn\n",
      "3       winter\n",
      "4       winter\n",
      "         ...  \n",
      "1374    summer\n",
      "1375    winter\n",
      "1376    spring\n",
      "1377    spring\n",
      "1378    summer\n",
      "Name: BinnedMoSold, Length: 1379, dtype: object\n",
      "Updated cols: \n",
      " ['YearBuilt_cat', 'BinnedMoSold', 'OverallQual', 'GrLivArea', 'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1', 'GarageCars', 'FullBath', 'GarageArea', 'LotArea', 'MasVnrArea', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'BsmtUnfSF', 'BsmtQual', 'LotFrontage', 'OpenPorchSF', 'OverallCond', 'GarageType', 'WoodDeckSF', 'TotRmsAbvGrd', 'MSSubClass', 'MoSold', 'BsmtExposure', 'LotShape', 'MSZoning', 'BedroomAbvGr', 'MasVnrType', 'ExterQual', 'HalfBath', 'FireplaceQu', 'KitchenQual', 'Condition1', 'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType', 'SalePrice'] \n",
      "\n",
      "Updated DATA:  Index(['YearBuilt_cat', 'BinnedMoSold', 'OverallQual', 'GrLivArea',\n",
      "       'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1', 'GarageCars',\n",
      "       'FullBath', 'GarageArea', 'LotArea', 'MasVnrArea', 'YearRemodAdd',\n",
      "       'GarageYrBlt', 'BsmtUnfSF', 'BsmtQual', 'LotFrontage', 'OpenPorchSF',\n",
      "       'OverallCond', 'GarageType', 'WoodDeckSF', 'TotRmsAbvGrd', 'MSSubClass',\n",
      "       'BsmtExposure', 'LotShape', 'MSZoning', 'BedroomAbvGr', 'MasVnrType',\n",
      "       'ExterQual', 'HalfBath', 'FireplaceQu', 'KitchenQual', 'Condition1',\n",
      "       'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType',\n",
      "       'SalePrice'],\n",
      "      dtype='object')\n",
      "Updated Numerical Attributes: \n",
      " ['YearRemodAdd', 'OverallQual', 'MSSubClass', 'OverallCond', 'GarageYrBlt'] \n",
      "\n",
      "Original Categorical Attributes:  ['BsmtQual', 'GarageType', 'BsmtExposure', 'LotShape', 'MSZoning', 'MasVnrType', 'ExterQual', 'FireplaceQu', 'KitchenQual', 'Condition1', 'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType']\n",
      "Updated Categorical Attributes: \n",
      " ['YearBuilt_cat', 'BinnedMoSold', 'BsmtQual', 'GarageType', 'BsmtExposure', 'LotShape', 'MSZoning', 'MasVnrType', 'ExterQual', 'FireplaceQu', 'KitchenQual', 'Condition1', 'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType']\n",
      "YearBuilt_cat    0\n",
      "BinnedMoSold     0\n",
      "OverallQual      0\n",
      "GrLivArea        0\n",
      "TotalBsmtSF      0\n",
      "2ndFlrSF         0\n",
      "1stFlrSF         0\n",
      "BsmtFinSF1       0\n",
      "GarageCars       0\n",
      "FullBath         0\n",
      "GarageArea       0\n",
      "LotArea          0\n",
      "MasVnrArea       0\n",
      "YearRemodAdd     0\n",
      "GarageYrBlt      0\n",
      "BsmtUnfSF        0\n",
      "BsmtQual         0\n",
      "LotFrontage      0\n",
      "OpenPorchSF      0\n",
      "OverallCond      0\n",
      "GarageType       0\n",
      "WoodDeckSF       0\n",
      "TotRmsAbvGrd     0\n",
      "MSSubClass       0\n",
      "BsmtExposure     0\n",
      "LotShape         0\n",
      "MSZoning         0\n",
      "BedroomAbvGr     0\n",
      "MasVnrType       0\n",
      "ExterQual        0\n",
      "HalfBath         0\n",
      "FireplaceQu      0\n",
      "KitchenQual      0\n",
      "Condition1       0\n",
      "BldgType         0\n",
      "SaleCondition    0\n",
      "Street           0\n",
      "PavedDrive       0\n",
      "SaleType         0\n",
      "SalePrice        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata_ohe = pd.get_dummies(data)\\ndata2 = pd.get_dummies(data, columns=categorical_cols)\\ndata_ohe.head()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "import numpy as np\n",
    "\n",
    "# find how many different years are there to decide if need to bin it\n",
    "# print (\"nunique: \\n\", data.nunique())\n",
    "\n",
    "unique_years = len(np.sort(data['YearBuilt'].unique()))\n",
    "print (\"Unique Years: \", unique_years, '\\n')\n",
    "\n",
    "# print (np.sort(data['MoSold'].unique()))\n",
    "# Gets the list of existing column names, this will be used later for adding the new columns to the front of the list\n",
    "existing_cols = list(data.columns.values)\n",
    "print (\"existing columns: \\n\", existing_cols, '\\n')\n",
    "\n",
    "# we can either bin the years into pre-1900, 1901-1920, 1921-1930, etc. or simple create 10 bins\n",
    "myLabels = ['1880-1900', '1901-1910', '1911-1920', '1921-1930', '1931-1940', \n",
    "            '1941-1950', '1951-1960', '1961-1970', '1971-1980', '1981-1990', \n",
    "            '1991-2000', '2001-2010']\n",
    "\n",
    "# Ref: https://dfrieds.com/data-analysis/bin-values-python-pandas.html\n",
    "# Convert new column from 'category' to 'string' type so that encoding can happen properly\n",
    "# Ref: https://stackoverflow.com/questions/46775308/pandas-cut-how-to-convert-categorical-labels-to-strings-otherwise-cannot-expor\n",
    "data[\"YearBuilt_cat\"] = pd.cut(data[\"YearBuilt\"],\n",
    "                               bins=[1880, 1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010],\n",
    "                               labels=myLabels, include_lowest=True).astype(str)\n",
    "print (\"sorted: \\n\", data.YearBuilt_cat.value_counts().sort_index(), '\\n')\n",
    "\n",
    "# One way to bin the months is to divide the months into different seasons, if we think there is some seasonal pattern\n",
    "spring = [3,4,5]\n",
    "summer = [6,7,8]\n",
    "autumn = [9,10,11]\n",
    "winter = [12,1,2]\n",
    "\n",
    "def month_to_season(month):\n",
    "    if month in spring: \n",
    "        return 'spring'\n",
    "    if month in summer:\n",
    "        return 'summer'\n",
    "    if month in autumn:\n",
    "        return 'autumn'\n",
    "    if month in winter:\n",
    "        return 'winter'\n",
    "    \n",
    "data['BinnedMoSold'] = data['MoSold'].map(month_to_season)\n",
    "print (\"Binned Month Sold: \\n\", data['BinnedMoSold'])\n",
    "\n",
    "# add the new columns to the front, for easier feature/target separation later\n",
    "new_cols = ['YearBuilt_cat', 'BinnedMoSold'] + existing_cols\n",
    "print (\"Updated cols: \\n\", new_cols, '\\n')\n",
    "\n",
    "# Ref: https://www.kite.com/python/answers/how-to-reorder-columns-in-a-pandas-dataframe-in-python\n",
    "data = data.reindex(columns=new_cols)\n",
    "\n",
    "# drop all the transformed columns\n",
    "# print (\"Before drop: \\n\", data.columns)\n",
    "data.drop(columns=['MoSold', 'YearBuilt'], axis=1, inplace=True)\n",
    "# data1 = data.drop(columns=['MoSold', 'YearBuilt'], axis=1)\n",
    "# print (\"After drop: \\n\", data.columns)\n",
    "\n",
    "print ('Updated DATA: ', data.columns)\n",
    "\n",
    "# Removed the dropped colmns from the num_attribs list\n",
    "cols_removed = ['MoSold', 'YearBuilt']\n",
    "num_attribs = [ele for ele in num_attribs if ele not in cols_removed]\n",
    "print ('Updated Numerical Attributes: \\n', num_attribs, '\\n')\n",
    "print ('Original Categorical Attributes: ', cat_attribs)\n",
    "\n",
    "cat_attribs = list(data.select_dtypes(['object']).columns)\n",
    "print ('Updated Categorical Attributes: \\n', cat_attribs)\n",
    "\n",
    "print (data.isnull().sum())\n",
    "'''\n",
    "data_ohe = pd.get_dummies(data)\n",
    "data2 = pd.get_dummies(data, columns=categorical_cols)\n",
    "data_ohe.head()\n",
    "'''\n",
    "## END YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT2vnRP-TB3c",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 4 (5 marks)\n",
    "\n",
    "Use appropriate encoding for the categorical columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g2TkRE8bU0ct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features:  ['YearBuilt_cat', 'BinnedMoSold', 'BsmtQual', 'GarageType', 'BsmtExposure', 'LotShape', 'MSZoning', 'MasVnrType', 'ExterQual', 'FireplaceQu', 'KitchenQual', 'Condition1', 'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType'] \n",
      "\n",
      "Numercial Features:  ['YearRemodAdd', 'OverallQual', 'MSSubClass', 'OverallCond', 'GarageYrBlt'] \n",
      "\n",
      "data_preprocessed columns: \n",
      " RangeIndex(start=0, stop=207, step=1) Total Columns (Pre-processed):  (1379, 207)\n",
      "data_preprocessed: \n",
      "        0    1    2    3    4    5    6    7    8    9    10   11   12   13   \\\n",
      "1374  10.0  2.0  3.0  1.0  4.0  3.0  3.0  2.0  3.0  5.0  3.0  2.0  0.0  4.0   \n",
      "1375   8.0  3.0  2.0  1.0  3.0  3.0  3.0  3.0  3.0  5.0  3.0  2.0  0.0  4.0   \n",
      "1376   5.0  1.0  4.0  1.0  3.0  3.0  3.0  2.0  0.0  2.0  2.0  2.0  0.0  4.0   \n",
      "1377   5.0  1.0  4.0  1.0  2.0  3.0  3.0  2.0  3.0  3.0  2.0  2.0  0.0  4.0   \n",
      "1378   7.0  2.0  4.0  1.0  3.0  3.0  3.0  2.0  2.0  3.0  3.0  2.0  0.0  4.0   \n",
      "\n",
      "      14   15   16   17   18   19   20   21   22   23   24   25   26   27   \\\n",
      "1374  1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      28   29   30   31   32   33   34   35   36   37   38   39   40   41   \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      42   43   44   45   46   47   48   49   50   51   52   53   54   55   \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      56   57   58   59   60   61   62   63   64   65   66   67   68   69   \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      70   71   72   73   74   75   76   77   78   79   80   81   82   83   \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "1376  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "\n",
      "      84   85   86   87   88   89   90   91   92   93   94   95   96   97   \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      98   99   ...  107  108  109  110  111  112  113  114  115  116  117  \\\n",
      "1374  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      118  119  120  121  122  123  124  125  126  127  128  129  130  131  \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      132  133  134  135  136  137  138  139  140  141  142  143  144  145  \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      146  147  148  149  150  151  152  153  154  155  156  157  158  159  \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      160  161  162  163  164  165  166  167  168  169  170  171  172  173  \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      174  175  176  177  178  179  180  181  182  183  184  185  186  187  \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      188  189  190  191  192  193  194  195  196  197  198  199  200  201  \\\n",
      "1374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1378  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      202  203  204  205  206  \n",
      "1374  0.0  0.0  0.0  0.0  0.0  \n",
      "1375  0.0  0.0  0.0  0.0  0.0  \n",
      "1376  0.0  0.0  0.0  0.0  0.0  \n",
      "1377  0.0  0.0  0.0  0.0  0.0  \n",
      "1378  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 207 columns]\n",
      "Combined: \n",
      " ['YearRemodAdd', 'OverallQual', 'MSSubClass', 'OverallCond', 'GarageYrBlt', 'YearBuilt_cat', 'BinnedMoSold', 'BsmtQual', 'GarageType', 'BsmtExposure', 'LotShape', 'MSZoning', 'MasVnrType', 'ExterQual', 'FireplaceQu', 'KitchenQual', 'Condition1', 'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType'] Total Columns (Categorical + Numerical):  22\n",
      "Original Columns: \n",
      " Index(['YearBuilt_cat', 'BinnedMoSold', 'OverallQual', 'GrLivArea',\n",
      "       'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1', 'GarageCars',\n",
      "       'FullBath', 'GarageArea', 'LotArea', 'MasVnrArea', 'YearRemodAdd',\n",
      "       'GarageYrBlt', 'BsmtUnfSF', 'BsmtQual', 'LotFrontage', 'OpenPorchSF',\n",
      "       'OverallCond', 'GarageType', 'WoodDeckSF', 'TotRmsAbvGrd', 'MSSubClass',\n",
      "       'BsmtExposure', 'LotShape', 'MSZoning', 'BedroomAbvGr', 'MasVnrType',\n",
      "       'ExterQual', 'HalfBath', 'FireplaceQu', 'KitchenQual', 'Condition1',\n",
      "       'BldgType', 'SaleCondition', 'Street', 'PavedDrive', 'SaleType',\n",
      "       'SalePrice'],\n",
      "      dtype='object')\n",
      "Data Remaining Columns: \n",
      " Index(['GrLivArea', 'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1',\n",
      "       'GarageCars', 'FullBath', 'GarageArea', 'LotArea', 'MasVnrArea',\n",
      "       'BsmtUnfSF', 'LotFrontage', 'OpenPorchSF', 'WoodDeckSF', 'TotRmsAbvGrd',\n",
      "       'BedroomAbvGr', 'HalfBath', 'SalePrice'],\n",
      "      dtype='object') Total Dimension:  (1379, 18)\n",
      "Data Cleaned Columns: \n",
      " Index([             0,              1,              2,              3,\n",
      "                    4,              5,              6,              7,\n",
      "                    8,              9,\n",
      "       ...\n",
      "            'LotArea',   'MasVnrArea',    'BsmtUnfSF',  'LotFrontage',\n",
      "        'OpenPorchSF',   'WoodDeckSF', 'TotRmsAbvGrd', 'BedroomAbvGr',\n",
      "           'HalfBath',    'SalePrice'],\n",
      "      dtype='object', length=225) Total Dimension \n",
      " (1379, 225)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>...</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>548.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>460.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>608.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>642.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>836.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   10   11   12   13   14  \\\n",
       "0  11.0  3.0  2.0  1.0  3.0  3.0  3.0  1.0  2.0  3.0  2.0  2.0  0.0  4.0  1.0   \n",
       "1   8.0  1.0  2.0  1.0  1.0  3.0  3.0  2.0  3.0  5.0  3.0  1.0  0.0  4.0  1.0   \n",
       "2  11.0  0.0  2.0  1.0  2.0  0.0  3.0  1.0  2.0  5.0  2.0  2.0  0.0  4.0  1.0   \n",
       "3   2.0  3.0  4.0  5.0  3.0  0.0  3.0  2.0  3.0  2.0  2.0  2.0  0.0  0.0  1.0   \n",
       "4  10.0  3.0  2.0  1.0  0.0  0.0  3.0  1.0  2.0  5.0  2.0  2.0  0.0  4.0  1.0   \n",
       "\n",
       "    15   16   17   18   19   20   21   22   23   24   25   26   27   28   29  \\\n",
       "0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    30   31   32   33   34   35   36   37   38   39   40   41   42   43   44  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    45   46   47   48   49   50   51   52   53   54   55   56   57   58   59  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    60   61   62   63   64   65   66   67   68   69   70   71   72   73   74  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    75   76   77   78   79   80   81   82   83   84   85   86   87   88   89  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    90   91   92   93   94   95   96   97   98   99  ...  125  126  127  128  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   144  145  146  147  148  149  150  151  152  153  154  155  156  157  158  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   159  160  161  162  163  164  165  166  167  168  169  170  171  172  173  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   174  175  176  177  178  179  180  181  182  183  184  185  186  187  188  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   189  190  191  192  193  194  195  196  197  198  199  200  201  202  203  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   204  205  206  GrLivArea  TotalBsmtSF  2ndFlrSF  1stFlrSF  BsmtFinSF1  \\\n",
       "0  0.0  0.0  0.0     1710.0        856.0     854.0     856.0       706.0   \n",
       "1  0.0  0.0  0.0     1262.0       1262.0       0.0    1262.0       978.0   \n",
       "2  0.0  0.0  0.0     1786.0        920.0     866.0     920.0       486.0   \n",
       "3  0.0  0.0  0.0     1717.0        756.0     756.0     961.0       216.0   \n",
       "4  0.0  0.0  0.0     2198.0       1145.0    1053.0    1145.0       655.0   \n",
       "\n",
       "   GarageCars  FullBath  GarageArea  LotArea  MasVnrArea  BsmtUnfSF  \\\n",
       "0           2         2       548.0   8450.0       196.0      150.0   \n",
       "1           2         2       460.0   9600.0         0.0      284.0   \n",
       "2           2         2       608.0  11250.0       162.0      434.0   \n",
       "3           3         1       642.0   9550.0         0.0      540.0   \n",
       "4           3         2       836.0  14260.0       350.0      490.0   \n",
       "\n",
       "   LotFrontage  OpenPorchSF  WoodDeckSF  TotRmsAbvGrd  BedroomAbvGr  HalfBath  \\\n",
       "0         65.0         61.0         0.0             8             3         1   \n",
       "1         80.0          0.0       298.0             6             3         0   \n",
       "2         68.0         42.0         0.0             6             3         1   \n",
       "3         60.0         35.0         0.0             7             3         0   \n",
       "4         84.0         84.0       192.0             9             4         1   \n",
       "\n",
       "   SalePrice  \n",
       "0   208500.0  \n",
       "1   181500.0  \n",
       "2   223500.0  \n",
       "3   140000.0  \n",
       "4   250000.0  \n",
       "\n",
       "[5 rows x 225 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "print (\"Categorical Features: \", cat_attribs, '\\n')\n",
    "print (\"Numercial Features: \", num_attribs, '\\n')\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (OrdinalEncoder(), cat_attribs), # # Use: OrdinalEncoder, LabelEncoder for categorical features\n",
    "    (OneHotEncoder(), num_attribs), # use: OneHotEncoder, LabelBinarizer for numerical feature\n",
    "    #remainder='passthrough'\n",
    ")\n",
    "df_transformed = ct.fit_transform(data)\n",
    "\n",
    "data_preprocessed = pd.DataFrame(df_transformed.toarray(), index=data.index)\n",
    "print ('data_preprocessed columns: \\n', data_preprocessed.columns, 'Total Columns (Pre-processed): ', data_preprocessed.shape)\n",
    "print ('data_preprocessed: \\n', data_preprocessed.tail())\n",
    "\n",
    "combined_num_cat_attribs = num_attribs + cat_attribs\n",
    "print (\"Combined: \\n\", combined_num_cat_attribs, 'Total Columns (Categorical + Numerical): ', len(combined_num_cat_attribs))\n",
    "print (\"Original Columns: \\n\", data.columns)\n",
    "data_remaining = data.drop(combined_num_cat_attribs, axis=1)\n",
    "print ('Data Remaining Columns: \\n', data_remaining.columns, 'Total Dimension: ', data_remaining.shape)\n",
    "\n",
    "data_cleaned = pd.concat([data_preprocessed, data_remaining], axis=1)\n",
    "print ('Data Cleaned Columns: \\n', data_cleaned.columns, 'Total Dimension \\n', data_cleaned.shape)\n",
    "data_cleaned.head()\n",
    "## START YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48z7AaTtTB3g",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 5 (5 marks)\n",
    "- Separate your data into features and target label ('SalePrice') columns. \n",
    "- Create train/test splits. Decide on the most appropriate splitting strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1DhyLUwlTB3h",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data cleaned:  (1379, 225)\n",
      "X_train:  <class 'pandas.core.frame.DataFrame'> x_test:  <class 'pandas.core.frame.DataFrame'> Y_train:  <class 'pandas.core.series.Series'> y_test:  <class 'pandas.core.series.Series'>\n",
      "X_train:  (1103, 224) x_test:  (276, 224) Y_train:  (1103,) y_test:  (276,)\n",
      "X_train:           0    1    2    3    4    5    6    7    8    9   10   11   12   13  \\\n",
      "643    9.0  0.0  2.0  1.0  2.0  0.0  3.0  2.0  2.0  5.0  2.0  2.0  4.0  4.0   \n",
      "863    3.0  2.0  4.0  5.0  3.0  3.0  4.0  2.0  3.0  3.0  3.0  2.0  0.0  0.0   \n",
      "426   11.0  2.0  3.0  1.0  4.0  3.0  1.0  2.0  2.0  3.0  2.0  2.0  0.0  4.0   \n",
      "1146   7.0  1.0  4.0  1.0  0.0  0.0  3.0  2.0  3.0  3.0  3.0  2.0  0.0  4.0   \n",
      "752    4.0  2.0  2.0  5.0  3.0  3.0  3.0  1.0  3.0  5.0  2.0  1.0  0.0  4.0   \n",
      "\n",
      "       14   15   16   17   18   19   20   21   22   23   24   25   26   27  \\\n",
      "643   1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   1.0  2.0  8.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   1.0  2.0  8.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       28   29   30   31   32   33   34   35   36   37   38   39   40   41  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       42   43   44   45   46   47   48   49   50   51   52   53   54   55  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       56   57   58   59   60   61   62   63   64   65   66   67   68   69  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       70   71   72   73   74   75   76   77   78   79   80   81   82   83  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "\n",
      "       84   85   86   87   88   89   90   91   92   93   94   95   96   97  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       98   99  ...  124  125  126  127  128  129  130  131  132  133  134  \\\n",
      "643   0.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      135  136  137  138  139  140  141  142  143  144  145  146  147  148  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      149  150  151  152  153  154  155  156  157  158  159  160  161  162  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      163  164  165  166  167  168  169  170  171  172  173  174  175  176  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      177  178  179  180  181  182  183  184  185  186  187  188  189  190  \\\n",
      "643   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      191  192  193  194  195  196  197  198  199  200  201  202  203  204  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      205  206  GrLivArea  TotalBsmtSF  2ndFlrSF  1stFlrSF  BsmtFinSF1  \\\n",
      "643   0.0  0.0     2090.0       1190.0     900.0    1190.0       828.0   \n",
      "863   0.0  0.0     1015.0        768.0       0.0    1015.0       489.0   \n",
      "426   0.0  0.0     1590.0        768.0     804.0     786.0         0.0   \n",
      "1146  0.0  0.0      960.0        648.0       0.0     960.0       648.0   \n",
      "752   0.0  0.0     1768.0        731.0     787.0     981.0       569.0   \n",
      "\n",
      "      GarageCars  FullBath  GarageArea  LotArea  MasVnrArea  BsmtUnfSF  \\\n",
      "643            2         2       577.0   5062.0         0.0      180.0   \n",
      "863            1         1       450.0   6120.0         0.0      279.0   \n",
      "426            2         2       676.0   9000.0         0.0      768.0   \n",
      "1146           1         0       364.0  10246.0         0.0        0.0   \n",
      "752            1         1       240.0   7200.0       252.0      162.0   \n",
      "\n",
      "      LotFrontage  OpenPorchSF  WoodDeckSF  TotRmsAbvGrd  BedroomAbvGr  \\\n",
      "643     59.911111          0.0       219.0             6             3   \n",
      "863     51.000000          0.0         0.0             6             3   \n",
      "426     75.000000         30.0         0.0             6             3   \n",
      "1146    59.911111          0.0        88.0             3             0   \n",
      "752     60.000000          0.0         0.0             7             3   \n",
      "\n",
      "      HalfBath  \n",
      "643          0  \n",
      "863          0  \n",
      "426          1  \n",
      "1146         0  \n",
      "752          1  \n",
      "\n",
      "[5 rows x 224 columns]\n"
     ]
    }
   ],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print ('data cleaned: ', data_cleaned.shape)\n",
    "# print ('SalePrice \\n', data_cleaned.iloc[:, 224])\n",
    "#print (data_cleaned.columns)\n",
    "#print (len(data_cleaned.columns))\n",
    "#col_idx = data_cleaned.columns.get_loc('SalePrice')\n",
    "#print (col_idx)\n",
    "\n",
    "target_col_idx = len(data_cleaned.columns) - 1\n",
    "# X_train, x_test, Y_train, y_test = train_test_split(data_cleaned.iloc[:, :224], data_cleaned.iloc[:, 224], \n",
    "#                                                     test_size = 0.2, shuffle=True, random_state=7)\n",
    "\n",
    "X_train, x_test, Y_train, y_test = train_test_split(data_cleaned.iloc[:, :target_col_idx], data_cleaned.iloc[:, target_col_idx], \n",
    "                                                    test_size = 0.2, shuffle=True, random_state=7)\n",
    "\n",
    "print ('X_train: ', type(X_train), 'x_test: ', type(x_test), 'Y_train: ', type(Y_train), 'y_test: ', type(y_test))\n",
    "print ('X_train: ', X_train.shape, 'x_test: ', x_test.shape, 'Y_train: ', Y_train.shape, 'y_test: ', y_test.shape)\n",
    "\n",
    "print ('X_train: ', X_train.head())\n",
    "## END YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBHECC6NTB3k",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 6 (7 marks)\n",
    "\n",
    "* Scale the all the numerical (non categorical) features using one of the following: `StandardScaler`, `MinMaxScaler`\n",
    "* Be sure to fit the scaler on *ONLY* the training data, but then apply it to both the train and test data identically.\n",
    "* Optional: You may also want to calculate the skewness of your numeric features and decide if you need to do log transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "df6zIjVMU0cw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 'GrLivArea', 'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1', 'GarageArea', 'LotArea', 'MasVnrArea', 'BsmtUnfSF', 'LotFrontage', 'OpenPorchSF', 'WoodDeckSF']\n",
      "Type:  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == np.float64:\n",
    "        numeric_cols.append(col)\n",
    "print(numeric_cols)\n",
    "\n",
    "print ('Type: ', type(numeric_cols))\n",
    "# Ref: https://www.geeksforgeeks.org/python-pandas-index-dtype/\n",
    "numeric_cols = pd.Index(numeric_cols)\n",
    "\n",
    "# Ref: https://www.debugcn.com/en/article/39567566.html. If use above code snippet w/o converting to Pandas Index.dtype\n",
    "# will cause columntransformer to fail!!\n",
    "# numeric_cols = X_train.select_dtypes(include=np.float64).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "giZnzvCYU0cx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1    2    3    4    5    6    7    8    9   10   11   12   13  \\\n",
      "643    9.0  0.0  2.0  1.0  2.0  0.0  3.0  2.0  2.0  5.0  2.0  2.0  4.0  4.0   \n",
      "863    3.0  2.0  4.0  5.0  3.0  3.0  4.0  2.0  3.0  3.0  3.0  2.0  0.0  0.0   \n",
      "426   11.0  2.0  3.0  1.0  4.0  3.0  1.0  2.0  2.0  3.0  2.0  2.0  0.0  4.0   \n",
      "1146   7.0  1.0  4.0  1.0  0.0  0.0  3.0  2.0  3.0  3.0  3.0  2.0  0.0  4.0   \n",
      "752    4.0  2.0  2.0  5.0  3.0  3.0  3.0  1.0  3.0  5.0  2.0  1.0  0.0  4.0   \n",
      "\n",
      "       14   15   16   17   18   19   20   21   22   23   24   25   26   27  \\\n",
      "643   1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   1.0  2.0  8.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  1.0  2.0  8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   1.0  2.0  8.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       28   29   30   31   32   33   34   35   36   37   38   39   40   41  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       42   43   44   45   46   47   48   49   50   51   52   53   54   55  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       56   57   58   59   60   61   62   63   64   65   66   67   68   69  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       70   71   72   73   74   75   76   77   78   79   80   81   82   83  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "\n",
      "       84   85   86   87   88   89   90   91   92   93   94   95   96   97  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "       98   99  ...  124  125  126  127  128  129  130  131  132  133  134  \\\n",
      "643   0.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      135  136  137  138  139  140  141  142  143  144  145  146  147  148  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      149  150  151  152  153  154  155  156  157  158  159  160  161  162  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      163  164  165  166  167  168  169  170  171  172  173  174  175  176  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      177  178  179  180  181  182  183  184  185  186  187  188  189  190  \\\n",
      "643   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      191  192  193  194  195  196  197  198  199  200  201  202  203  204  \\\n",
      "643   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "863   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "426   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "1146  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "752   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "      205  206  GrLivArea  TotalBsmtSF  2ndFlrSF  1stFlrSF  BsmtFinSF1  \\\n",
      "643   0.0  0.0     2090.0       1190.0     900.0    1190.0       828.0   \n",
      "863   0.0  0.0     1015.0        768.0       0.0    1015.0       489.0   \n",
      "426   0.0  0.0     1590.0        768.0     804.0     786.0         0.0   \n",
      "1146  0.0  0.0      960.0        648.0       0.0     960.0       648.0   \n",
      "752   0.0  0.0     1768.0        731.0     787.0     981.0       569.0   \n",
      "\n",
      "      GarageCars  FullBath  GarageArea  LotArea  MasVnrArea  BsmtUnfSF  \\\n",
      "643            2         2       577.0   5062.0         0.0      180.0   \n",
      "863            1         1       450.0   6120.0         0.0      279.0   \n",
      "426            2         2       676.0   9000.0         0.0      768.0   \n",
      "1146           1         0       364.0  10246.0         0.0        0.0   \n",
      "752            1         1       240.0   7200.0       252.0      162.0   \n",
      "\n",
      "      LotFrontage  OpenPorchSF  WoodDeckSF  TotRmsAbvGrd  BedroomAbvGr  \\\n",
      "643     59.911111          0.0       219.0             6             3   \n",
      "863     51.000000          0.0         0.0             6             3   \n",
      "426     75.000000         30.0         0.0             6             3   \n",
      "1146    59.911111          0.0        88.0             3             0   \n",
      "752     60.000000          0.0         0.0             7             3   \n",
      "\n",
      "      HalfBath  \n",
      "643          0  \n",
      "863          0  \n",
      "426          1  \n",
      "1146         0  \n",
      "752          1  \n",
      "\n",
      "[5 rows x 224 columns]\n",
      "[[ 0.44452208 -1.68444128 -0.79313964 ...  6.          3.\n",
      "   0.        ]\n",
      " [-1.58854434  0.55000097  1.0862009  ...  6.          3.\n",
      "   0.        ]\n",
      " [ 1.12221088  0.55000097  0.14653063 ...  6.          3.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.57201113 -1.68444128  1.0862009  ...  4.          2.\n",
      "   0.        ]\n",
      " [-2.60507755  1.66722209  0.14653063 ... 11.          4.\n",
      "   0.        ]\n",
      " [ 1.12221088  0.55000097 -2.67248019 ...  5.          0.\n",
      "   1.        ]]\n",
      "643     207500.0\n",
      "863      88000.0\n",
      "426     210000.0\n",
      "1146    145000.0\n",
      "752     175000.0\n",
      "          ...   \n",
      "211     106000.0\n",
      "502     178000.0\n",
      "537     120000.0\n",
      "1220    107500.0\n",
      "175     286000.0\n",
      "Name: SalePrice, Length: 1103, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "ct = make_column_transformer(\n",
    "    (std_scaler, numeric_cols),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "print (X_train.head())\n",
    "X_train_scaled = ct.fit_transform(X_train)\n",
    "\n",
    "# Y_train_scaled = std_scaler.fit_transform(Y_train.values.reshape(-1, 1))\n",
    "\n",
    "print (X_train_scaled)\n",
    "# print (Y_train_scaled)\n",
    "print (Y_train)\n",
    "\n",
    "# x_test_scaled = ct.fit_transform(x_test)\n",
    "x_test_scaled = ct.transform(x_test)\n",
    "# y_test_scaled = std_scaler.fit_transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16.534759453898094 37.13488925525427\n",
      "Data highly skewed!!\n"
     ]
    }
   ],
   "source": [
    "# Test Skewess\n",
    "print (data_cleaned.skew().min(), data_cleaned.skew().max())\n",
    "print ('Data highly skewed!!')\n",
    "\n",
    "# log tranform - data columns have too many 0's in them resulting in NaN!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVnd4iNPTB3p"
   },
   "source": [
    "### Question 7 (5 marks)\n",
    "\n",
    "* Fit a Linear Regression model on the training data. Apply regularization if necessary. \n",
    "* Calculate the mean squared error on both the train and test set\n",
    "* Calculate the R-square error on both train and test set \n",
    "\n",
    "What can you conclude from the result? \n",
    "\n",
    "_Type your answer here_\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "The large value for the MSE indicates that the model accuracy is bad. The ideal case is for the MSE to be as close to zero as possible.\n",
    "\n",
    "The negative R2 score indicates that the chosen model (Linear Regression) does not follow the trend of the data, so it fits worse than a horizontal line i.e. linear regression fits the data really poorly.\n",
    "\n",
    "**Lasso & Ridge Regression**\n",
    "\n",
    "Applying Lasso and Ridge regularization seemed to improve model accuracy as evidenced by the big drop in RMSE. The best possible R2 score is 1. So the closer the value it is to 1 as evidenced in Lasso and Ridge regression, means the more precisely the model is able to predict the sale price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Percentage Error\n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44452208, -1.68444128, -0.79313964, ...,  6.        ,\n",
       "         3.        ,  0.        ],\n",
       "       [-1.58854434,  0.55000097,  1.0862009 , ...,  6.        ,\n",
       "         3.        ,  0.        ],\n",
       "       [ 1.12221088,  0.55000097,  0.14653063, ...,  6.        ,\n",
       "         3.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.57201113, -1.68444128,  1.0862009 , ...,  4.        ,\n",
       "         2.        ,  0.        ],\n",
       "       [-2.60507755,  1.66722209,  0.14653063, ..., 11.        ,\n",
       "         4.        ,  0.        ],\n",
       "       [ 1.12221088,  0.55000097, -2.67248019, ...,  5.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wFD0lAnOTB3q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_rmse:  237320621191345.28\n",
      "lr_r2_score:  -8.230608030759833e+18 \n",
      "\n",
      "lasso_rmse:  40798.273040816486\n",
      "lasso r2 score:  0.7567546611077797 \n",
      "\n",
      "lasso_rmse:  40784.797863240216\n",
      "ridge r2 score:  0.7569153165761255 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18506100940.277832, tolerance: 670676335.171703\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "## START YOUR CODE HERE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "# lr.fit(X_train_scaled, Y_train_scaled)\n",
    "lr.fit(X_train_scaled, Y_train)\n",
    "\n",
    "'''\n",
    "lr_predictions = lr.predict(x_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "'''\n",
    "lr_predictions = lr.predict(x_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "print ('lr_rmse: ', lr_rmse)\n",
    "\n",
    "'''\n",
    "lr_r2_score = r2_score(y_test, lr_predictions)\n",
    "'''\n",
    "lr_r2_score = r2_score(y_test, lr_predictions)\n",
    "print ('lr_r2_score: ', lr_r2_score, '\\n')\n",
    "\n",
    "# Lasso\n",
    "# Ref: https://www.askpython.com/python/examples/lasso-regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso = lasso_model.fit(X_train_scaled , Y_train)\n",
    "lasso_predictions = lasso.predict(x_test_scaled)\n",
    "lasso_MAPE = MAPE(y_test, lasso_predictions)\n",
    "# print(\"MAPE value: \", lasso_MAPE)\n",
    "Accuracy = 100 - lasso_MAPE\n",
    "# print('Accuracy of Lasso Regression: {:0.2f}%.'.format(Accuracy))\n",
    "\n",
    "lasso_mse = mean_squared_error(y_test, lasso_predictions)\n",
    "lasso_rmse = np.sqrt(lasso_mse)\n",
    "print ('lasso_rmse: ', lasso_rmse)\n",
    "lasso_r2_score = r2_score(y_test, lasso_predictions)\n",
    "print ('lasso r2 score: ', lasso_r2_score, '\\n')\n",
    "\n",
    "# Ridge\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge = ridge_model.fit(X_train_scaled , Y_train)\n",
    "ridge_predictions = ridge.predict(x_test_scaled)\n",
    "ridge_MAPE = MAPE(y_test, ridge_predictions)\n",
    "# print(\"MAPE value: \", ridge_MAPE)\n",
    "Accuracy = 100 - ridge_MAPE\n",
    "# print('Accuracy of Ridge Regression: {:0.2f}%.'.format(Accuracy))\n",
    "\n",
    "ridge_mse = mean_squared_error(y_test, ridge_predictions)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "print ('lasso_rmse: ', ridge_rmse)\n",
    "\n",
    "ridge_r2_score = r2_score(y_test, ridge_predictions)\n",
    "print ('ridge r2 score: ', ridge_r2_score, '\\n')\n",
    "## END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x_-ito9U0c0"
   },
   "source": [
    "### Question 8 (5 marks)\n",
    "\n",
    "* Now train a RandomForestRegressor by using `RandomForestRegressor(n_estimators=30)`\n",
    "* Find the MSE and R-sqaure score on both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0-5fCYaqU0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr_rmse:  35947.63505879593\n",
      "rfr_r2_score:  0.8111566852835044\n"
     ]
    }
   ],
   "source": [
    "## START YOUR CODE HERE ##\n",
    "rfr = RandomForestRegressor(n_estimators = 30, random_state = 8)\n",
    "# Ref: https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected\n",
    "# rfr.fit(X_train_scaled, Y_train.ravel())\n",
    "rfr.fit(X_train_scaled, Y_train)\n",
    "\n",
    "\n",
    "#rfr_predictions = rfr.predict(x_test)\n",
    "#rfr_mse = mean_squared_error(y_test, rfr_predictions)\n",
    "\n",
    "rfr_predictions = rfr.predict(x_test_scaled)\n",
    "rfr_mse = mean_squared_error(y_test, rfr_predictions)\n",
    "\n",
    "rfr_rmse = np.sqrt(rfr_mse)\n",
    "print ('rfr_rmse: ', rfr_rmse)\n",
    "\n",
    "\n",
    "#rfr_r2_score = r2_score(y_test, rfr_predictions)\n",
    "\n",
    "rfr_r2_score = r2_score(y_test, rfr_predictions)\n",
    "\n",
    "print ('rfr_r2_score: ', rfr_r2_score)\n",
    "\n",
    "## END YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4Xl4cCnTB3t",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 9 (4 marks)\n",
    "\n",
    "Plot predicted prices vs actual prices for the RandomForestRegressor model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Tda-WcgeU0c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ref: https://towardsdatascience.com/random-forest-ca80e56224c1\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# ax = sns.distplot(y_test_scaled, hist=False, color='r', label='Acutal Prices')\n",
    "# ax = sns.distplot(y_test, hist=False, color='r', label='Acutal Prices')\n",
    "# sns.distplot(rfr_predictions, hist=False, color='b', label='Predicted Prices', ax=ax)\n",
    "plt.scatter(y_test, rfr_predictions, c='crimson')\n",
    "plt.xlabel('Actual Values', fontsize=15)\n",
    "plt.ylabel('Predicted Values', fontsize=15)\n",
    "plt.axis('equal')\n",
    "\n",
    "p1 = max(max(rfr_predictions), max(y_test))\n",
    "p2 = min(min(rfr_predictions), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "\n",
    "# Ref: https://stackoverflow.com/questions/44968012/unable-to-show-legend-in-seaborn-distplot\n",
    "# plt.legend()\n",
    "plt.title('Actual vs. Predicted Prices')\n",
    "plt.show()\n",
    "## END YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7P0amO1xTB3w"
   },
   "source": [
    "### Question 10 (2 marks)\n",
    "\n",
    "What can you conclude from the plot?\n",
    "\n",
    "_Type your answer here_\n",
    "\n",
    "From the graph, it is observed that the model appears to predict the prices fairly well. If we draw a straight line through the points, we observe that most of the data values are clusterd along the straight line. Having said that, there are a number of outliers. At actual price (210K), the predicted value was around 350K and another was predicted at 560K. At the higher end, actual value (750K), predicted value was lower around 550K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xa_s7NSlU0c3"
   },
   "source": [
    "### Question 11 (2 marks)\n",
    "\n",
    "Noticed that we did not ask you to evaluate the result on the validation set, as our train set is pretty small (less than 1000 samples). We can however, use K-fold cross-validation to evaluate our model. \n",
    "\n",
    "- Use 5-fold cross-validation to train and evaluate our model (use RandomForestRegressor)\n",
    "- Compute the average MSEs across all folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KqC456ORU0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 643,  863,  426, 1146,  752,  747, 1224,   96,  603, 1253,\n",
      "            ...\n",
      "             345,  535, 1209, 1372,  919,  211,  502,  537, 1220,  175],\n",
      "           dtype='int64', length=1103)\n",
      "[(1, 1808856182.5442233), (2, 1027381900.2644897), (3, 514660752.40422326), (4, 759642598.1107727), (5, 719282441.7895705)]\n",
      "Average mse across folds:  965964775.0226558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Ref: https://financetrain.com/k-fold-cross-validation-example-python-scikit-learn/\n",
    "\n",
    "# We use enumerate() to return also the index position of the list so that we can print out the fold number\n",
    "\n",
    "'''\n",
    "How enumerate(iterable, startIndex) works\n",
    "mylist = ['A', 'B' ,'C', 'D']\n",
    "e_list = enumerate(mylist)\n",
    "print(list(e_list))\n",
    "[(0, 'A'), (1, 'B'), (2, 'C'), (3, 'D')]\n",
    "'''\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=8)\n",
    "print (Y_train.index)\n",
    "# Ref: https://towardsdatascience.com/complete-guide-to-pythons-cross-validation-with-examples-a9676b5cac12\n",
    "# Ref: https://medium.datadriveninvestor.com/k-fold-cross-validation-6b8518070833\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    #print('Train Index: \\n', train_index)\n",
    "    #print ('Test Index: \\n', test_index)\n",
    "    '''\n",
    "    X_train_1 = X_train_scaled[train_index]\n",
    "    x_test_1 = X_train_scaled[test_index]\n",
    "    Y_train_1 = Y_train.iloc[train_index]\n",
    "    y_test_1 = Y_train.iloc[test_index]\n",
    "    '''\n",
    "    X_train_1, x_test_1, Y_train_1, y_test_1 = X_train_scaled[train_index], X_train_scaled[test_index], Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "    rfr.fit(X_train_1, Y_train_1)\n",
    "    #scores.append(rfr.score(x_test_1, y_test_1))\n",
    "    rfr_predictions_1 = rfr.predict(x_test_1)\n",
    "    rfr_mse_1 = mean_squared_error(y_test_1, rfr_predictions_1)\n",
    "    scores.append(rfr_mse_1)\n",
    "    '''\n",
    "    rfr_predictions = rfr.predict(x_test)\n",
    "    rfr_mse = mean_squared_error(y_test, rfr_predictions)\n",
    "    rfr_rmse = np.sqrt(lr_mse)\n",
    "    print ('rfr_rmse: ', rfr_rmse)\n",
    "    '''\n",
    "\n",
    "print(list(enumerate(scores, 1)))\n",
    "print ('Average mse across folds: ', sum(scores)/len(scores))\n",
    "# Ref: https://www.kaggle.com/satishgunjal/tutorial-k-fold-cross-validation\n",
    "# score = cross_val_score(rfr, X, y, cv= kf, scoring=\"mean_squared_error\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "2021S1_ml_assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "name": "Train_Test_Splits_Regularization_Exercises-ANSWERS",
  "notebookId": 2125319687183944
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
